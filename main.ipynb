{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Imports & Setup`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k:\\GIT\\mentor_group_side_project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >>> Config Variables <<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"full\", \"first_half\", \"second_half\", \"random_10\"\n",
    "row_range = \"full\"\n",
    "\n",
    "# { find_top_k } number of paragraphs that have the highest similarity score with the policy and search terms will be used to generate the prompt.\n",
    "find_top_k = 4\n",
    "\n",
    "# score of similarity = { policy_weight } * cosine_similarity between policy and paragraph + { 1 - policy_weight } * cosine_similarity between policy and search terms\n",
    "policy_weight = 0.95\n",
    "\n",
    "# { extracting_model } will be used to extract the policy details by using the policy name and the search terms.\n",
    "extracting_model = \"deepseek-r1:8b\"\n",
    "\n",
    "# { embedding_model } will be used to generate the embeddings for the policy and the paragraphs.\n",
    "embedding_model = {\"gpu\": \"intfloat/e5-base\", \"cpu\": \"nomic-embed-text\"}\n",
    "\n",
    "# { prompt_version } is the version of the prompt template to be used.\n",
    "prompt_version = \"v3\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = device.type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress_bar(iteration, total, prefix='', length=40, start_time=None, line_width=256):\n",
    "    elapsed = time.time() - start_time if start_time else 0\n",
    "    avg_time = elapsed / iteration if iteration > 0 else 0\n",
    "    eta = avg_time * (total - iteration)\n",
    "\n",
    "    percent = f\"{100 * (iteration / float(total)):.1f}\"\n",
    "    filled_length = int(length * iteration // total)\n",
    "    bar_color = '\\033[31m'\n",
    "    bar = bar_color + '█' * filled_length + '-' * (length - filled_length) + '\\033[0m'\n",
    "\n",
    "    eta_min = int(eta // 60)\n",
    "    eta_sec = int(eta % 60)\n",
    "\n",
    "    line = f\"|{bar}| {percent}% Complete | ETA: {eta_min}m {eta_sec}s | {prefix}\"\n",
    "    padded_line = line.ljust(line_width)\n",
    "\n",
    "    sys.stdout.write('\\r' + padded_line)\n",
    "    sys.stdout.flush()\n",
    "def split_text_into_paragraphs(text, chunk_size=3, merge_headings=True):\n",
    "    \"\"\"Split policy text into N-sentence chunks.\"\"\"\n",
    "\n",
    "    # Fix encoding and glued terms (e.g. BenchmarkRate → Benchmark Rate)\n",
    "    text = text.replace(\"�\", \" \").replace(\"•\", \"*\")\n",
    "    text = re.sub(r'(?<=[a-z])(?=[A-Z])', ' ', text)        # aB → a B\n",
    "    text = re.sub(r'(?<=\\d)(?=[A-Z])', ' ', text)           # 25Years → 25 Years\n",
    "    text = re.sub(r'(?<=[a-zA-Z])(?=\\d)', ' ', text)        # abc123 → abc 123\n",
    "    text = re.sub(r'(?<=[a-z])(?=[A-Z][a-z])', '. ', text)  # add inferred periods\n",
    "\n",
    "    # Normalize spacing\n",
    "    text = re.sub(r'\\n{2,}', '\\n', text)      # collapse double line breaks\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # remove excess whitespace\n",
    "\n",
    "    # Split at likely section headings\n",
    "    sections = re.split(r'\\n(?=[A-Z][^\\n]{3,60}\\n)', text)\n",
    "\n",
    "    tokenizer = PunktSentenceTokenizer()\n",
    "    chunks = []\n",
    "\n",
    "    for section in sections:\n",
    "        section = section.strip()\n",
    "        if not section:\n",
    "            continue\n",
    "\n",
    "        # Convert bullet-style lines into full sentences\n",
    "        section = re.sub(r\"\\n\\s*\\*\\s*\", \". \", section)\n",
    "        section = re.sub(r\"\\*\\s*\", \"\", section)\n",
    "\n",
    "        # Break before heading-like phrases\n",
    "        section = re.sub(r'(?<=\\. )([A-Z][^\\n]{3,60})(?= )', r'\\n\\1', section)\n",
    "\n",
    "        sentences = tokenizer.tokenize(section)\n",
    "\n",
    "        # Attach short heading-only lines to previous chunk\n",
    "        if merge_headings and len(sentences) <= 1 and chunks:\n",
    "            chunks[-1] += \" \" + section\n",
    "            continue\n",
    "\n",
    "        # Group into N-sentence chunks\n",
    "        for i in range(0, len(sentences), chunk_size):\n",
    "            chunk = \" \".join(sentences[i:i + chunk_size])\n",
    "            chunks.append(chunk.strip())\n",
    "\n",
    "    return chunks\n",
    "def get_embedding(text):\n",
    "    if device == \"cuda\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained(embedding_model[\"gpu\"])\n",
    "        model = AutoModel.from_pretrained(embedding_model[\"gpu\"]).to(\"cuda\")\n",
    "        \n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "        \n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        return embeddings.cpu().detach().numpy().tolist()[0]\n",
    "    else:\n",
    "        model = embedding_model[\"cpu\"]\n",
    "        \n",
    "        url = \"http://localhost:11434/api/embed\"\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"input\": text\n",
    "        }\n",
    "        response = requests.post(url, json=payload)\n",
    "        return response.json()[\"embeddings\"][0]\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1, vec2 = np.array(vec1), np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "def generate_prompt(policy_of_interest, policy_of_interest_embedding, paragraph_embeddings, search_terms_synonyms_embedding):\n",
    "    most_related_paragraphs = []\n",
    "\n",
    "    for index in range(len(paragraph_embeddings)):\n",
    "        score = policy_weight * cosine_similarity(policy_of_interest_embedding, paragraph_embeddings[index]) + (1 - policy_weight) * cosine_similarity(search_terms_synonyms_embedding, paragraph_embeddings[index])\n",
    "        most_related_paragraphs.append((paragraphs[index], score))\n",
    "        \n",
    "    most_related_paragraphs.sort(key=lambda x: x[1], reverse=True)\n",
    "    most_related_paragraphs = most_related_paragraphs[:find_top_k]\n",
    "    combined_paragraphs = \"\\n\".join([p[0] for p in most_related_paragraphs])\n",
    "    \n",
    "    prompt_v3 = f\"\"\"\n",
    "        You are an expert in policy analysis. Your task is to extract **form-related policies** from the document titled *Policies_Meridian.docx*.\n",
    "        \n",
    "        1. **Explicitly stated** - directly and clearly mentioned in the text.\n",
    "        2. **Implicitly referenced** - indirectly indicated, embedded within procedures, or inferred from documentation context.\n",
    "\n",
    "        ---\n",
    "        \n",
    "        ### Document Content:\n",
    "        Below is a selection of paragraphs extracted from *Policies_Meridian.docx*:\n",
    "        \n",
    "        {combined_paragraphs}\n",
    "        \n",
    "        ---\n",
    "\n",
    "        ### Target Policy:\n",
    "        - Policy of Interest: **\"{policy_of_interest}\"**\n",
    "        - Search Term Synonyms: **\"{search_terms_synonyms}\"**\n",
    "        \n",
    "        Use these keywords and any related concepts to locate relevant policies. \n",
    "        Remember to extract not just explicit mentions but also policies that are implied or embedded in procedures.\n",
    "        Do **not** guess or make assumptions. Only mark a policy as found if there is **clear textual evidence**.\n",
    "        \n",
    "        ---\n",
    "        \n",
    "        ### Output Instructions:\n",
    "        \n",
    "        For **each policy instance** found, provide the following:\n",
    "\n",
    "        1. **Y/N/M**:\n",
    "        - `\"Y\"` - Clearly mentioned (explicitly and unambiguously stated).\n",
    "        - `\"M\"` - Mentioned indirectly (implied, inferred, or part of a procedure).\n",
    "        - `\"N\"` - The policy does not appear in the document in any clear or inferable form.\n",
    "        ⛔ Do not guess. If unsure, default to `\"N\"`.\n",
    "\n",
    "        2. **POLICY DETAILS**:\n",
    "        - Provide the specific content from the document that explains what the policy is about, including any wording, numbers, or requirements mentioned.\n",
    "\n",
    "        ---\n",
    "    \"\"\".strip()\n",
    "    prompt_v2 = f\"\"\"\n",
    "        You are an expert in policy analysis. Your task is to extract **form-related policies** from the document titled *Policies_Meridian.docx*.\n",
    "    \n",
    "        ---\n",
    "        \n",
    "        ### Document Content:\n",
    "        Below is a selection of paragraphs extracted from *Policies_Meridian.docx*:\n",
    "        \n",
    "        {combined_paragraphs}\n",
    "        \n",
    "        ---\n",
    "\n",
    "        ### Target Policy:\n",
    "        - Policy of Interest: **\"{policy_of_interest}\"**\n",
    "        - Search Term Synonyms: **\"{search_terms_synonyms}\"**\n",
    "        \n",
    "        Use these keywords and any related concepts to locate relevant policies. \n",
    "        Remember to extract not just explicit mentions but also policies that are implied or embedded in procedures.\n",
    "        Do **not** guess or make assumptions. Only mark a policy as found if there is **clear textual evidence**.\n",
    "        \n",
    "        ---\n",
    "        \n",
    "        ### Output Instructions:\n",
    "        \n",
    "        For **each policy instance** found, provide the following:\n",
    "\n",
    "        1. **Y/N/M**:\n",
    "        - `\"Y\"` - Clearly mentioned (explicitly and unambiguously stated).\n",
    "        - `\"M\"` - Mentioned indirectly (implied, inferred, or part of a procedure).\n",
    "        - `\"N\"` - The policy does not appear in the document in any clear or inferable form.\n",
    "\n",
    "        2. **POLICY DETAILS**:\n",
    "        - Provide the specific content from the document that explains what the policy is about, including any wording, numbers, or requirements mentioned.\n",
    "\n",
    "        ---\n",
    "    \"\"\".strip()\n",
    "    prompt_v1 = f\"\"\"\n",
    "        You are an expert in policy analysis. Your task is to extract **form-related policies** from the document titled *Policies_Meridian.docx*. These policies may be:\n",
    "\n",
    "        1. **Explicitly stated** - directly mentioned in the text.\n",
    "        2. **Implicitly referenced** - embedded within procedures, documentation processes, or described indirectly without using the exact policy names.\n",
    "\n",
    "        ---\n",
    "        \n",
    "        ### Document Content:\n",
    "        Below is the full content of *Policies_Meridian.docx*:\n",
    "        \n",
    "        {combined_paragraphs}\n",
    "        \n",
    "        ---\n",
    "\n",
    "        ### Target Policy:\n",
    "        - Policy of Interest: **\"{policy_of_interest}\"**\n",
    "        - Search Term Synonyms: **\"{search_terms_synonyms}\"**\n",
    "        \n",
    "        Use these keywords and any related concepts to locate relevant policies. \n",
    "        Remember to extract not just explicit mentions but also policies that are implied or embedded in procedures.\n",
    "        This document is used for important decision-making. Ensure no relevant information is overlooked, whether it's directly stated or subtly implied.\n",
    "        \n",
    "        ---\n",
    "        \n",
    "        ### Output Instructions:\n",
    "        \n",
    "        For **each policy instance** found, provide the following:\n",
    "\n",
    "        1. **Status**:\n",
    "        - \"Y\" - Clearly mentioned (explicitly and unambiguously stated).\n",
    "        - \"M\" - Mentioned indirectly (implied, inferred, or part of a procedure).\n",
    "        - \"N\" - Not found (no relevant mention in the document).\n",
    "\n",
    "        2. **POLICY DETAILS**:\n",
    "        - Provide the specific content from the document that explains what the policy is about, including any wording, numbers, or requirements mentioned.\n",
    "        - If no policy is found, leave this field empty, returning \"\".\n",
    "        - If the Response is \"N\", the field should be empty, returning \"\".\n",
    "\n",
    "        ---\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    if prompt_version == \"v1\":\n",
    "        prompt = prompt_v1\n",
    "    elif prompt_version == \"v2\":\n",
    "        prompt = prompt_v2\n",
    "    elif prompt_version == \"v3\":\n",
    "        prompt = prompt_v3\n",
    "    else:\n",
    "        raise ValueError(\"Invalid prompt version. Use 'v1' or 'v2'.\")\n",
    "\n",
    "    return prompt\n",
    "def request_extracted_policy_detail_from_ollama(prompt, policy_of_interest):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": extracting_model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"format\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"Y/N/M\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"Y\", \"M\", \"N\"]\n",
    "                },\n",
    "                \"POLICY DETAILS\": {\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"Y/N/M\", \"POLICY DETAILS\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    response = response.json()\n",
    "    response_data = response['response']\n",
    "    response_data = json.loads(response_data)\n",
    "    response_data[\"POLICY NAME\"] = policy_of_interest\n",
    "    response_data = json.dumps(response_data)\n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Load & Preprocess`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load DOCX and embedding them into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/preprocessed_data/policies_meridian_plaintext.txt\", \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "    policies_meridian_plaintext = \"\\n\".join(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k:\\GIT\\mentor_group_side_project\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\u001b[31m████████████████████████████████████████\u001b[0m| 100.0% Complete | ETA: 0m 0s | Embeddings                                   "
     ]
    }
   ],
   "source": [
    "paragraphs = split_text_into_paragraphs(policies_meridian_plaintext)\n",
    "paragraph_embeddings = []\n",
    "\n",
    "start_time = time.time()\n",
    "for p in paragraphs:\n",
    "   paragraph_embeddings.append(get_embedding(p))\n",
    "   print_progress_bar(len(paragraph_embeddings), len(paragraphs), prefix=\"Embeddings\", start_time=start_time, line_width=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Policies & Search Terms Synonyms and embedding them into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k:\\GIT\\mentor_group_side_project\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\u001b[31m███-------------------------------------\u001b[0m| 8.1% Complete | ETA: 2m 2s | Embeddings                                     "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/preprocessed_data/policies_to_update.csv\")\n",
    "df = df.drop(index=[0,1])\n",
    "df = df.drop(columns=[\"Y/N/M\", \"POLICY DETAILS\", \"Prompt\"])\n",
    "if row_range == \"full\":\n",
    "    df = df.iloc[0:len(df)]\n",
    "elif row_range == \"first_half\":\n",
    "    df = df.iloc[0:len(df)//2]\n",
    "elif row_range == \"second_half\":\n",
    "    df = df.iloc[len(df)//2:len(df)]\n",
    "elif row_range == \"random_10\":\n",
    "    df = df.sample(n=10, random_state=42)\n",
    "else:\n",
    "    df = df.iloc[0:len(df)]\n",
    " \n",
    "policy_of_interests = df[\"POLICY NAME\"].tolist()\n",
    "search_terms_synonyms = df[\"Search Terms Synonyms\"].tolist()\n",
    "policy_of_interest_embeddings = []\n",
    "search_terms_synonyms_embeddings = []\n",
    "\n",
    "start_time = time.time()\n",
    "for p in policy_of_interests:\n",
    "    policy_of_interest_embeddings.append(get_embedding(p))\n",
    "    print_progress_bar(len(policy_of_interest_embeddings), len(policy_of_interests), prefix=\"Embeddings\", start_time=start_time, line_width=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\u001b[31m████████████████████████████████████████\u001b[0m| 100.0% Complete | ETA: 0m 0s | Embeddings                                   "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for s in search_terms_synonyms:\n",
    "    search_terms_synonyms_embeddings.append(get_embedding(str(s)))\n",
    "    print_progress_bar(len(search_terms_synonyms_embeddings), len(search_terms_synonyms), prefix=\"Embeddings\", start_time=start_time, line_width=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Generate Table`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through each policy of interest and generate the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\u001b[31m████████████████████████████████████████\u001b[0m| 100.0% Complete | ETA: 0m 0s | 79 N's | NICHES → M                                                                                                                                                          "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "prompts = []\n",
    "parsed_results = []\n",
    "n_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for i, policy_of_interest in enumerate(policy_of_interests):\n",
    "    policy_of_interest_embedding = policy_of_interest_embeddings[i]\n",
    "    search_terms_synonyms_embedding = search_terms_synonyms_embeddings[i]\n",
    "    prompt = generate_prompt(policy_of_interest, policy_of_interest_embedding, paragraph_embeddings, search_terms_synonyms_embedding)\n",
    "    prompts.append(prompt)\n",
    "\n",
    "for i, policy_of_interest in enumerate(policy_of_interests):\n",
    "    extracted_policy_detail = request_extracted_policy_detail_from_ollama(prompts[i], policy_of_interest)\n",
    "    results.append(extracted_policy_detail)\n",
    "\n",
    "    try:\n",
    "        detail_dict = json.loads(extracted_policy_detail)\n",
    "        parsed_results.append(detail_dict)\n",
    "        \n",
    "        if detail_dict.get(\"Y/N/M\", \"\").strip() == \"N\":\n",
    "            n_count += 1\n",
    "            status = \"N\"\n",
    "        elif detail_dict.get(\"Y/N/M\", \"\").strip() == \"Y\":\n",
    "            status = \"Y\"\n",
    "        elif detail_dict.get(\"Y/N/M\", \"\").strip() == \"M\":\n",
    "            status = \"M\"\n",
    "        else:\n",
    "            status = \"ERROR\"\n",
    "\n",
    "    except Exception as e:\n",
    "        parsed_results.append({\n",
    "            \"POLICY NAME\": policy_of_interest,\n",
    "            \"Y/N/M\": \"ERROR\",\n",
    "            \"POLICY DETAILS\": f\"Failed to parse: {str(e)}\"\n",
    "        })\n",
    "        status = \"Parse Error\"\n",
    "\n",
    "    print_progress_bar(i + 1, len(policy_of_interests), \n",
    "                       prefix=f\"{n_count } N's | {policy_of_interest} → {status}\",\n",
    "                       start_time=start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformat the response into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(parsed_results)\n",
    "results_df = results_df[[\"Y/N/M\", \"POLICY NAME\", \"POLICY DETAILS\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date_time = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "os.makedirs(current_date_time, exist_ok=True)\n",
    "results_df.to_csv(f\"./{current_date_time}/extracted_policy_details.csv\", index=False)\n",
    "with open(f\"./{current_date_time}/config_variables.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"find_top_k: {find_top_k}\\n\")\n",
    "    f.write(f\"policy_weight: {policy_weight}\\n\")\n",
    "    f.write(f\"extracting_model: {extracting_model}\\n\")\n",
    "    f.write(f\"embedding_model: {embedding_model}\\n\")\n",
    "    f.write(f\"prompt_version: {prompt_version}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y/N/M</th>\n",
       "      <th>POLICY NAME</th>\n",
       "      <th>POLICY DETAILS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>BFS (CMHC Program)</td>\n",
       "      <td>The maximum number of properties a client can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>BFS ALT-A</td>\n",
       "      <td>The policy states that 'lending areas' are res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>BFS Stated Income (Bank Statements)</td>\n",
       "      <td>The property must be a laneway house, coach ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>BFS Stated Income (Conventional)</td>\n",
       "      <td>The maximum number of properties a borrower ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "      <td>BFS Stated Income (Sagen &amp; CG Program)</td>\n",
       "      <td>The property must be on land that is no larger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Y</td>\n",
       "      <td>Cash Back Mortgages</td>\n",
       "      <td>The policy includes a 'Tarion warranty require...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Y</td>\n",
       "      <td>Collateral Switch/Transfer</td>\n",
       "      <td>This policy outlines the requirements for usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Y</td>\n",
       "      <td>Construction</td>\n",
       "      <td>The lender requires a minimum population requi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Y</td>\n",
       "      <td>Cottage/Recreational Properties</td>\n",
       "      <td>The document explicitly states that 'a maximum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Y</td>\n",
       "      <td>Equity Program</td>\n",
       "      <td>The policy explicitly states that properties w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Y/N/M                             POLICY NAME  \\\n",
       "0     Y                      BFS (CMHC Program)   \n",
       "1     Y                               BFS ALT-A   \n",
       "2     Y     BFS Stated Income (Bank Statements)   \n",
       "3     Y        BFS Stated Income (Conventional)   \n",
       "4     Y  BFS Stated Income (Sagen & CG Program)   \n",
       "5     Y                     Cash Back Mortgages   \n",
       "6     Y              Collateral Switch/Transfer   \n",
       "7     Y                            Construction   \n",
       "8     Y         Cottage/Recreational Properties   \n",
       "9     Y                          Equity Program   \n",
       "\n",
       "                                      POLICY DETAILS  \n",
       "0  The maximum number of properties a client can ...  \n",
       "1  The policy states that 'lending areas' are res...  \n",
       "2  The property must be a laneway house, coach ho...  \n",
       "3  The maximum number of properties a borrower ca...  \n",
       "4  The property must be on land that is no larger...  \n",
       "5  The policy includes a 'Tarion warranty require...  \n",
       "6  This policy outlines the requirements for usin...  \n",
       "7  The lender requires a minimum population requi...  \n",
       "8  The document explicitly states that 'a maximum...  \n",
       "9  The policy explicitly states that properties w...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
