{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Preprocess the Local Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining all necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_paragraphs(text):\n",
    "    paragraphs = re.split(r'\\n{2,}', text)\n",
    "    return [p.strip() for p in paragraphs if p.strip()]\n",
    "def get_embedding(text, model=\"nomic-embed-text\"):\n",
    "    url = \"http://localhost:11434/api/embed\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"input\": text\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    return response.json()[\"embeddings\"][0]\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1, vec2 = np.array(vec1), np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local policies and embadding into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/preprocessed_data/policies_meridian_plaintext.txt\", \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "    policies_meridian_plaintext = \"\\n\".join(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = split_text_into_paragraphs(policies_meridian_plaintext)\n",
    "paragraph_embeddings = []\n",
    "for p in paragraphs:\n",
    "    paragraph_embeddings.append(get_embedding(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load all policies and embedding them into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/preprocessed_data/policies_to_update.csv\")\n",
    "df = df.drop(index=[0,1])\n",
    "df = df.drop(columns=[\"Y/N/M\", \"POLICY DETAILS\", \"Prompt\"])\n",
    "# only keep the last 10 rows\n",
    "df = df.tail(10)\n",
    "\n",
    "policy_of_interests = df[\"POLICY NAME\"].tolist()\n",
    "search_terms_synonyms = df[\"Search Terms Synonyms\"].tolist()\n",
    "policy_of_interest_embeddings = []\n",
    "\n",
    "for p in policy_of_interests:\n",
    "    policy_of_interest_embeddings.append(get_embedding(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending the Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining all necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(policy_of_interest, policy_of_interest_embedding, paragraph_embeddings):\n",
    "    find_top_k = 6\n",
    "    most_related_paragraphs = []\n",
    "\n",
    "    for index in range(len(paragraph_embeddings)):\n",
    "        score = cosine_similarity(policy_of_interest_embedding, paragraph_embeddings[index])\n",
    "        most_related_paragraphs.append((paragraphs[index], score))\n",
    "        \n",
    "    most_related_paragraphs.sort(key=lambda x: x[1], reverse=True)\n",
    "    most_related_paragraphs = most_related_paragraphs[:find_top_k]\n",
    "    combined_paragraphs = \"\\n\".join([p[0] for p in most_related_paragraphs])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are to extract form-related policies from the attached 'Policies_Meridian.docx'. Focus on identifying both **explicit mentions** and **indirect references** (e.g., policies embedded in documentation procedures or described without using exact policy names).\n",
    "\n",
    "The 'Policies_Meridian.docx' file content is provided below:\n",
    "\n",
    "{combined_paragraphs}\n",
    "\n",
    "The policy of interest is \"{policy_of_interest}\" with Search Terms Synonyms \"{search_terms_synonyms}\" for targeting the location of that policy in the doc. \n",
    "Remember to extract not just explicit mentions but also policies that are implied or embedded in procedures.\n",
    "\n",
    "Output the result in the following format:\n",
    "\n",
    "{{\n",
    "    \"POLICY NAME\": \"Consent To Release Client Information\",\n",
    "    \"Y/N/M\": \"Y\",\n",
    "    \"POLICY DETAILS\": \"Meridian requires signed consent from all applicants prior to underwriting, but does not provide consent forms to brokers.\"\n",
    "}}\n",
    "\n",
    "For each item, say:\n",
    "- \"Y\" if it is clearly mentioned,\n",
    "- \"M\" if it is mentioned indirectly,\n",
    "- \"N\" if not found.\n",
    "\"\"\".strip()\n",
    "\n",
    "    return prompt\n",
    "def request_extracted_policy_detail_from_ollama(prompt, policy_of_interest):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"deepseek-r1:8b\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"format\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"POLICY NAME\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [policy_of_interest]\n",
    "                },\n",
    "                \"Y/N/M\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"Y\", \"M\", \"N\"]\n",
    "                },\n",
    "                \"POLICY DETAILS\": {\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"POLICY NAME\", \"Y/N/M\", \"POLICY DETAILS\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    response = response.json()\n",
    "    response_data = response['response']\n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through each policy of interest and generate the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for i, policy_of_interest in enumerate(policy_of_interests):\n",
    "    policy_of_interest_embedding = policy_of_interest_embeddings[i]\n",
    "    prompt = generate_prompt(policy_of_interest, policy_of_interest_embedding, paragraph_embeddings)\n",
    "    extracted_policy_detail = request_extracted_policy_detail_from_ollama(prompt, policy_of_interest)\n",
    "    results.append(extracted_policy_detail)\n",
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"../../data/preprocessed_data/extracted_policy_details.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
